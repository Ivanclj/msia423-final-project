{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Conda tensorflow for MAC\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, f1_score\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Churn_Modelling.csv\",index_col='RowNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CustomerId', 'Surname', 'CreditScore', 'Geography', 'Gender', 'Age',\n",
       "       'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
       "       'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "drop = ['CustomerId', 'Surname']\n",
    "data.drop(drop, axis=1, inplace=True)\n",
    "# create dummy for Geography and Gender\n",
    "Geography = pd.get_dummies(data['Geography'], drop_first=True)\n",
    "Gender = pd.get_dummies(data['Gender'], drop_first=True)\n",
    "data.drop(['Geography','Gender'],axis=1,inplace=True)\n",
    "# new dataframe after encode categorical variables as dummies\n",
    "data1 = pd.concat([data,Geography,Gender],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "75% train and 25% test random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 11)\n",
      "(3000, 11)\n"
     ]
    }
   ],
   "source": [
    "X = data1.drop('Exited', axis=1)\n",
    "y = data1['Exited']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crude XGBoost model to select 8 features based on information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(xtrain, ytrain, learnRate=0.1, maxDepth=3, numEstimators=100):\n",
    "    \"\"\"Function to apply crude xgboost algorithm on training data to select 8 features by gain.\n",
    "    \n",
    "    Args:\n",
    "        xtrain (DataFrame): A DataFrame with features.\n",
    "        ytrain (Series): A Series with correct class label.\n",
    "        learnRate (numeric, optional): Boosting learning rate. Default to 0.1.\n",
    "        maxDepth (numeric, optional): Maximum tree depth for base learners. Default to 3.\n",
    "        numEstimators (numeric, optional): Number of boosted trees to fit. Default to 100.\n",
    "    \n",
    "    Returns:\n",
    "        xgb (:obj:`xgboost.sklearn.XGBClassifier`): The xgboost classifier.    \n",
    "        selected_features (str): The features selected from the model.\n",
    "    \n",
    "    \"\"\"\n",
    "    # initialize the xgboost classifier\n",
    "    xgb_classifier = xgb.XGBClassifier(objective ='binary:logistic', learning_rate = learnRate,\n",
    "                                       max_depth = maxDepth, n_estimators = numEstimators)\n",
    "    \n",
    "    # fit the classifier on training data\n",
    "    xgb_classifier.fit(xtrain,ytrain)\n",
    "    \n",
    "    # get importance (information gain) for each feature\n",
    "    importance = xgb_classifier.get_booster().get_score(importance_type='gain')\n",
    "    # select 8 features with most gain\n",
    "    selected_features = []\n",
    "    for value in sorted(importance.values(), reverse=True)[:8]:\n",
    "        selected_features.append(list(importance.keys())[list(importance.values()).index(value)])\n",
    "    # print cumulative gain of selected features\n",
    "    cum_gain = 0\n",
    "    for feature in selected_features:\n",
    "        cum_gain += importance[feature]\n",
    "    print('cumulative gain of selected features is {:.4f}'.format(cum_gain/sum(importance.values())))\n",
    "    \n",
    "    return xgb_classifier, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumulative gain of selected features is 0.9380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'IsActiveMember',\n",
       " 'NumOfProducts',\n",
       " 'Germany',\n",
       " 'Male',\n",
       " 'Balance',\n",
       " 'HasCrCard',\n",
       " 'Tenure']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = feature_selection(X_train,y_train)\n",
    "xgb_bin = result[0]\n",
    "selected_features = result[1]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgboost.sklearn.XGBClassifier"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xgb_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. XGBoost\n",
    "2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_tuning(xtrain, ytrain, n_estimators, learning_rate, max_depth, selected_features):\n",
    "    \"\"\"Function to run xgboost grid search algorithm on training data to select best tuning parameters.\n",
    "    \n",
    "    Args:\n",
    "        xtrain (DataFrame): A DataFrame with features.\n",
    "        ytrain (Series): A Series with correct class label.\n",
    "        num_estimators (list): Number of boosted trees to fit.\n",
    "        learning_rate (list): Boosting learning rates.\n",
    "        max_depth (list): Maximum tree depths for base learners.\n",
    "        selected_features (list): A list of selected features to train the model on.\n",
    "    \n",
    "    Returns:\n",
    "        clf.best_estimator_ (:obj:`xgboost.sklearn.XGBClassifier`): The best xgboost classifier.\n",
    "    \n",
    "    \"\"\"\n",
    "    # initialize xgboost classifier\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    # prepare parameters for grid search\n",
    "    param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth)\n",
    "    # run grid search with different combinations of parameters\n",
    "    clf = GridSearchCV(xgb_model, param_grid, n_jobs=5, \n",
    "                       cv=StratifiedKFold(n_splits=5, shuffle=True), \n",
    "                       scoring='roc_auc',\n",
    "                       verbose=2, refit=True)\n",
    "    # fit model on training data\n",
    "    clf.fit(xtrain[selected_features], ytrain)\n",
    "    # return model with best combination of parameters\n",
    "    return clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=5)]: Done 320 out of 320 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [50, 100, 200, 300]\n",
    "learning_rate = [0.001, 0.01, 0.05, 0.1]\n",
    "max_depth = [3, 4, 5, 6]\n",
    "xgb_model = xgboost_tuning(X_train, y_train, n_estimators, learning_rate, max_depth, selected_features)\n",
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_tuning(xtrain, ytrain, n_estimators, max_depth, max_features, selected_features):\n",
    "    \"\"\"Function to run random forest grid search algorithm on training data to select best tuning parameters.\n",
    "    \n",
    "    Args:\n",
    "        xtrain (DataFrame): A DataFrame with features.\n",
    "        ytrain (Series): A Series with correct class label.\n",
    "        num_estimators (list): Number of trees in the forest.\n",
    "        max_depth (list): Maximum tree depths for base learners.\n",
    "        max_features (list): Max number of features considered for splitting a node.\n",
    "        selected_features (list): A list of selected features to train the model on.\n",
    "    \n",
    "    Returns:\n",
    "        rf_cv.best_estimator_ (:obj:`RandomForestClassifier`): The best random forest classifier.\n",
    "    \n",
    "    \"\"\"\n",
    "    # initialize xgboost classifier\n",
    "    rf = RandomForestClassifier()\n",
    "    # prepare parameters for grid search\n",
    "    param_grid = dict(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "    # run grid search with different combinations of parameters\n",
    "    rf_cv = GridSearchCV(rf, param_grid, n_jobs=5, \n",
    "                         cv=StratifiedKFold(n_splits=5, shuffle=True), \n",
    "                         scoring='roc_auc',\n",
    "                         verbose=2, refit=True)\n",
    "    # fit model on training data\n",
    "    rf_cv.fit(xtrain[selected_features], ytrain)\n",
    "    # return model with best combination of parameters\n",
    "    return rf_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=5)]: Done 320 out of 320 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features=4, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [50, 100, 200, 300]\n",
    "max_depth = [3, 4, 5, 6]\n",
    "max_features = [3, 4, 5, 6]\n",
    "rf = random_forest_tuning(X_train, y_train, n_estimators, max_depth, max_features, selected_features)\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features=4, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=6, max_features=4,n_estimators=300)\n",
    "rf.fit(X_train[selected_features],y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare AUC and F1 scores across\n",
    "1. Logistic Regression\n",
    "2. Random Forest\n",
    "3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model Training\n",
    "def logit(xtrain, ytrain, selected_features):\n",
    "    \"\"\"Function to run logistic regression algorithm on training data.\n",
    "    \n",
    "    Args:\n",
    "        xtrain (DataFrame): A DataFrame with features.\n",
    "        ytrain (Series): A Series with correct class label.\n",
    "        selected_features (list): A list of selected features to train the model on.\n",
    "    \n",
    "    Returns:\n",
    "        logmodel (:obj:`LogisticRegression`): The best xgboost classifier.\n",
    "    \n",
    "    \"\"\"\n",
    "    logmodel = LogisticRegression()\n",
    "    logmodel.fit(X_train[selected_features],y_train)\n",
    "    return logmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianfu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = logit(X_train, y_train, selected_features)\n",
    "logmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    \"\"\"Function to evaluate model performance on test data.\n",
    "    \n",
    "    Args:\n",
    "        model (:obj: model trained): Classification model trained.\n",
    "        test_features (DataFrame): A DataFrame as test set with selected features.\n",
    "        test_labels (Series): A Series with correct class label for test set.\n",
    "    \n",
    "    \"\"\"\n",
    "    # prediction results on test set\n",
    "    predictions = model.predict(test_features)\n",
    "\n",
    "    print('################### Model Performance ###################')\n",
    "    print(\"F1-score: \" + str(f1_score(y_test, predictions)))\n",
    "    print(\"AUC: \" + str(roc_auc_score(y_test, predictions)))\n",
    "    print()\n",
    "    print('################### Confusion Matrix ###################')\n",
    "    print(confusion_matrix(test_labels, predictions))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### Model Performance ###################\n",
      "F1-score: 0.0\n",
      "AUC: 0.5\n",
      "\n",
      "################### Confusion Matrix ###################\n",
      "[[2416    0]\n",
      " [ 584    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianfu/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate(logmodel, X_test[selected_features], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### Model Performance ###################\n",
      "F1-score: 0.5770491803278688\n",
      "AUC: 0.712161503220539\n",
      "\n",
      "################### Confusion Matrix ###################\n",
      "[[2349   67]\n",
      " [ 320  264]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(rf, X_test[selected_features], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### Model Performance ###################\n",
      "F1-score: 0.598941798941799\n",
      "AUC: 0.726152136441985\n",
      "\n",
      "################### Confusion Matrix ###################\n",
      "[[2338   78]\n",
      " [ 301  283]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(xgb_model, X_test[selected_features], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_prob(model, xtest, selected_features):\n",
    "    \"\"\"Function to generate predicted class probabilities for test data.\n",
    "    \n",
    "    Args:\n",
    "        model (:obj: model trained): Classification model trained.\n",
    "        xtest (Series): A DataFrame as test set with features.\n",
    "        selected_features (list): A list of selected features on which the model was trained.\n",
    "    \n",
    "    Returns:\n",
    "        churn_probs (numpy.ndarray): Predicted probability of churn for each observation in test.\n",
    "    \n",
    "    \"\"\"\n",
    "    probs = model.predict_proba(xtest[selected_features])\n",
    "    churn_probs = probs[:,1]\n",
    "    return churn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29073487, 0.24275398, 0.21948375, ..., 0.25452591, 0.29221372,\n",
       "       0.2868338 ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel_probs = predicted_prob(logmodel, X_test, selected_features)\n",
    "logmodel_probs\n",
    "#print(logmodel_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04316376, 0.06209654, 0.11456036, ..., 0.10320802, 0.01957687,\n",
       "       0.24430829])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_probs = predicted_prob(rf, X_test, selected_features)\n",
    "rf_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04434106, 0.03925258, 0.08520908, ..., 0.05524413, 0.01158028,\n",
       "       0.36693183], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_probs = predicted_prob(xgb_model, X_test, selected_features)\n",
    "xgb_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a248417f0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(rf_probs.tolist(),columns=['p_churn']).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFOlJREFUeJzt3X+QXeV93/H3x8gYB9kIG3uHCsVyGzmxx4wdvEPIeMZdGU+CoWPxh+ngklgwcjWTEI9bk4wVtzNJ23SqtENpIBknanAsXByZ0jrSYJyEyt66zgQSUTvIgBMEUUCIoDoIOWtwUpxv/7iHZiNW2rO79+6PZ9+vmZ095znPPef7rFafffacc8+mqpAktetlS12AJGm0DHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9NJJkkwm+dBS1yENi0EvSY0z6KURSrJmqWuQDHo1IcnhJD+b5KEkx5P8RpKzZnnNliRfS/KtJI8muWza5jck+b0kf5nkd5Oc171mIsmRGY79nm7555PcmeS/JPkWcG3XdkeS27r9PZhkfNhfA+lUDHq15BrgR4F/ALwJ+Jen6pjkYuA24GeAdcC7gMPTuvwT4Drg9cCZwE/PoY4twJ3dfm/v2t4H7Ona9gG/PIf9SQti0Kslv1xVT1TVM8C/BT5wmr7bgE9W1T1V9TdV9WRVfWPa9t+oqj+pqueBO4C3z6GO36+q3+r2+3zX9pWquruqvgt8GnjbHPYnLYhBr5Y8MW35z4C/d5q+G4BHT7P9z6ctPwesnWcdp9rfWZ6/12Ix6NWSDdOWvxc4epq+TzA4xTNX3wa+58WVJGcArzupj4+E1bJi0Ksl1ye5IMlrgI8Dnz1N31uB65JcmuRlSdYn+YEex/gTBrPxK5K8nMF1gFcsvHRpdAx6teQzwO8Cj3Ufv3CqjlX1Bwwutt4EnAD+J/CG2Q5QVSeAnwR+HXiSwQz/yGlfJC2x+IdH1IIkh4EPVdX/WOpapOXGGb0kNc6gV7OSfDzJ1AwfX1jq2qTF5KkbSWqcM3pJatyyeMPGeeedVxs3bpzXa7/97W9z9tlnD7egZc4xrw6OeXVYyJjvv//+b1bVye/jeIllEfQbN27kwIED83rt5OQkExMTwy1omXPMq4NjXh0WMuYkf9ann6duJKlxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpccvinbELcfDJE1y74/Oz9ju884pFqEaSlp9eM/ok65LcmeQbSR5O8sNJXpPkniSPdJ/P7fomyc1JDiV5IMlFox2CJOl0+p66+SXgt6vqB4C3AQ8DO4D9VbUJ2N+tA7wX2NR9bAc+MdSKJUlzMmvQJ3k18C4Gf0yZqvrrqnoW2ALs7rrtBq7slrcAt9XAvcC6JOcPvXJJUi+z/uGRJG8HdgEPMZjN3w98BHiyqtZN63e8qs5Nchews6q+0rXvBz5WVQdO2u92BjN+xsbG3rFnz555DeDYMyd4+vnZ+124/px57X85mpqaYu3atUtdxqJyzKuDY56bzZs3319V47P163Mxdg1wEfDhqrovyS/xt6dpZpIZ2l7y06SqdjH4AcL4+HjN9zGdt9y+lxsPzj6Mw9fMb//LkY9yXR0c8+qwGGPuc47+CHCkqu7r1u9kEPxPv3hKpvt8bFr/DdNefwFwdDjlSpLmatagr6o/B55I8v1d06UMTuPsA7Z2bVuBvd3yPuCD3d03lwAnquqp4ZYtSeqr7330HwZuT3Im8BhwHYMfEnck2QY8DlzV9b0buBw4BDzX9ZUkLZFeQV9VXwNmOuF/6Qx9C7h+gXVJkobERyBIUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuN6BX2Sw0kOJvlakgNd22uS3JPkke7zuV17ktyc5FCSB5JcNMoBSJJOby4z+s1V9faqGu/WdwD7q2oTsL9bB3gvsKn72A58YljFSpLmbiGnbrYAu7vl3cCV09pvq4F7gXVJzl/AcSRJC5Cqmr1T8qfAcaCAX6uqXUmerap10/ocr6pzk9wF7Kyqr3Tt+4GPVdWBk/a5ncGMn7GxsXfs2bNnXgM49swJnn5+9n4Xrj9nXvtfjqampli7du1Sl7GoHPPq4JjnZvPmzfdPO8tySmt67u+dVXU0yeuBe5J84zR9M0PbS36aVNUuYBfA+Ph4TUxM9Czl77rl9r3ceHD2YRy+Zn77X44mJyeZ79drpXLMq4NjHo1eQV9VR7vPx5J8DrgYeDrJ+VX1VHdq5ljX/QiwYdrLLwCODrHmedm44/O9+x7eecUIK5GkxTXrOfokZyd51YvLwI8AXwf2AVu7bluBvd3yPuCD3d03lwAnquqpoVcuSeqlz4x+DPhckhf7f6aqfjvJHwJ3JNkGPA5c1fW/G7gcOAQ8B1w39KolSb3NGvRV9Rjwthna/wK4dIb2Aq4fSnWSpAXznbGS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1LjeQZ/kjCRfTXJXt/7GJPcleSTJZ5Oc2bW/ols/1G3fOJrSJUl9zGVG/xHg4WnrvwjcVFWbgOPAtq59G3C8qr4PuKnrJ0laIr2CPskFwBXAr3frAd4N3Nl12Q1c2S1v6dbptl/a9ZckLYFU1eydkjuBfwe8Cvhp4Frg3m7WTpINwBeq6q1Jvg5cVlVHum2PAj9UVd88aZ/bge0AY2Nj79izZ8+8BnDsmRM8/fy8XnpKF64/Z7g7HLKpqSnWrl271GUsKse8Ojjmudm8efP9VTU+W781s3VI8o+AY1V1f5KJF5tn6Fo9tv1tQ9UuYBfA+Ph4TUxMnNyll1tu38uNB2cdxpwcvmZ+tSyWyclJ5vv1Wqkc8+rgmEejT0K+E3hfksuBs4BXA/8JWJdkTVW9AFwAHO36HwE2AEeSrAHOAZ4ZeuWSpF5mPUdfVT9bVRdU1UbgauCLVXUN8CXg/V23rcDebnlft063/YvV5/yQJGkkFnIf/ceAjyY5BLwWuLVrvxV4bdf+UWDHwkqUJC3EnE5uV9UkMNktPwZcPEOf7wBXDaE2SdIQ+M5YSWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0b7vN9G7Fxx+d79Tu884oRVyJJC+eMXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXGzBn2Ss5L8QZI/SvJgkn/Vtb8xyX1JHkny2SRndu2v6NYPdds3jnYIkqTT6TOj/yvg3VX1NuDtwGVJLgF+EbipqjYBx4FtXf9twPGq+j7gpq6fJGmJzBr0NTDVrb68+yjg3cCdXftu4MpueUu3Trf90iQZWsWSpDnpdY4+yRlJvgYcA+4BHgWeraoXui5HgPXd8nrgCYBu+wngtcMsWpLUX6+/MFVV3wXenmQd8DngzTN16z7PNHuvkxuSbAe2A4yNjTE5OdmnlJcYeyXccOELs3ccgfnWvFBTU1NLduyl4phXB8c8GnP6U4JV9WySSeASYF2SNd2s/QLgaNftCLABOJJkDXAO8MwM+9oF7AIYHx+viYmJeQ3gltv3cuPBpfmLiIevmViS405OTjLfr9dK5ZhXB8c8Gn3uunldN5MnySuB9wAPA18C3t912wrs7Zb3det0279YVS+Z0UuSFkefqfD5wO4kZzD4wXBHVd2V5CFgT5JfAL4K3Nr1vxX4dJJDDGbyV4+gbklST7MGfVU9APzgDO2PARfP0P4d4KqhVCdJWjDfGStJjVuaq5iN2Ljj8736Hd55xYgrkaRTc0YvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuNmDfokG5J8KcnDSR5M8pGu/TVJ7knySPf53K49SW5OcijJA0kuGvUgJEmn1mdG/wJwQ1W9GbgEuD7JW4AdwP6q2gTs79YB3gts6j62A58YetWSpN5mDfqqeqqq/ne3/JfAw8B6YAuwu+u2G7iyW94C3FYD9wLrkpw/9MolSb2kqvp3TjYCXwbeCjxeVeumbTteVecmuQvYWVVf6dr3Ax+rqgMn7Ws7gxk/Y2Nj79izZ8+8BnDsmRM8/fy8XrpoLlx/zlD3NzU1xdq1a4e6z+XOMa8OjnluNm/efH9Vjc/Wb03fHSZZC/w34J9V1beSnLLrDG0v+WlSVbuAXQDj4+M1MTHRt5S/45bb93Ljwd7DWBKHr5kY6v4mJyeZ79drpXLMq4NjHo1ed90keTmDkL+9qv571/z0i6dkus/HuvYjwIZpL78AODqcciVJc9XnrpsAtwIPV9V/nLZpH7C1W94K7J3W/sHu7ptLgBNV9dQQa5YkzUGfcx7vBH4cOJjka13bx4GdwB1JtgGPA1d12+4GLgcOAc8B1w21YknSnMwa9N1F1VOdkL90hv4FXL/Aupqyccfne/U7vPOKEVciaTXynbGS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDVueT8kZpXpe7/9py47e8SVSGqJM3pJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuP8wyMr0MEnT3Btjz9ScnjnFYtQjaTlbtYZfZJPJjmW5OvT2l6T5J4kj3Sfz+3ak+TmJIeSPJDkolEWL0maXZ9TN58CLjupbQewv6o2Afu7dYD3Apu6j+3AJ4ZTpiRpvmYN+qr6MvDMSc1bgN3d8m7gymntt9XAvcC6JOcPq1hJ0tylqmbvlGwE7qqqt3brz1bVumnbj1fVuUnuAnZW1Ve69v3Ax6rqwAz73M5g1s/Y2Ng79uzZM68BHHvmBE8/P6+Xrlhjr6TXmC9cf06v/R188kTvY/fd57BNTU2xdu3aJTn2UnHMq8NCxrx58+b7q2p8tn7DvhibGdpm/ElSVbuAXQDj4+M1MTExrwPecvtebjy4uq4p33DhC73GfPiaiV7763Nhd677HLbJyUnm+z2yUjnm1WExxjzf2yuffvGUTPf5WNd+BNgwrd8FwNH5lydJWqj5Bv0+YGu3vBXYO639g93dN5cAJ6rqqQXWKElagFl//0/ym8AEcF6SI8DPATuBO5JsAx4Hruq63w1cDhwCngOuG0HNkqQ5mDXoq+oDp9h06Qx9C7h+oUVJkobHRyBIUuNW1+0qq8zGOdxNI6ldzuglqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqc99FrToZ9b75/7lAaPWf0ktQ4g16SGmfQS1LjDHpJapwXY7Wk+l7c/dRlZy/Jcb1YrPlaqu/tmTijl6TGOaNXU4Z9++dc9ufsv30r9dHfBr1WhINPnuDaFfqfTFpqnrqRpMY5o5eGZLlf4PVdzauXQS8tsr6Be8OFL/Q6XWXgntpy/+G7WAx6SSM37FsNl/Ki+0rkOXpJapwzemmFW6rZ6CiO691Vo+GMXpIaN5KgT3JZkj9OcijJjlEcQ5LUz9CDPskZwK8A7wXeAnwgyVuGfRxJUj+jmNFfDByqqseq6q+BPcCWERxHktRDqmq4O0zeD1xWVR/q1n8c+KGq+qmT+m0Htner3w/88TwPeR7wzXm+dqVyzKuDY14dFjLmN1TV62brNIq7bjJD20t+mlTVLmDXgg+WHKiq8YXuZyVxzKuDY14dFmPMozh1cwTYMG39AuDoCI4jSephFEH/h8CmJG9MciZwNbBvBMeRJPUw9FM3VfVCkp8Cfgc4A/hkVT047ONMs+DTPyuQY14dHPPqMPIxD/1irCRpefGdsZLUOINekhq3IoJ+tkcqJHlFks922+9LsnHxqxyuHmP+aJKHkjyQZH+SNyxFncPW9/EZSd6fpJKs+Fvx+ow5yT/u/r0fTPKZxa5x2Hp8f39vki8l+Wr3PX75UtQ5LEk+meRYkq+fYnuS3Nx9PR5IctFQC6iqZf3B4ILuo8DfB84E/gh4y0l9fhL41W75auCzS133Iox5M/A93fJPrPQx9x131+9VwJeBe4Hxpa57Ef6tNwFfBc7t1l+/1HUvwph3AT/RLb8FOLzUdS9wzO8CLgK+fortlwNfYPA+pEuA+4Z5/JUwo+/zSIUtwO5u+U7g0iQzvXFrpZh1zFX1pap6rlu9l8H7FVa6vo/P+DfAvwe+s5jFjUifMf9T4Feq6jhAVR1b5BqHrc+YC3h1t3wOK/y9OFX1ZeCZ03TZAtxWA/cC65KcP6zjr4SgXw88MW39SNc2Y5+qegE4Abx2UaobjT5jnm4bg9nASjfruJP8ILChqu5azMJGqM+/9ZuANyX5vST3Jrls0aobjT5j/nngx5IcAe4GPrw4pS2Zuf6fn5OV8IdH+jxSoddjF1aQ3uNJ8mPAOPAPR1rR4jjtuJO8DLgJuHaxCloEff6t1zA4fTPB4De3/5XkrVX17IhrG5U+Y/4A8KmqujHJDwOf7sb8N6Mvb0mMNMNWwoy+zyMV/n+fJGsY/Kp3ul+Tlrtej5FI8h7gXwDvq6q/WqTaRmm2cb8KeCswmeQwg3OZ+1b4Bdm+3997q+r/VtWfMngA4KZFqm8U+ox5G3AHQFX9PnAWg4d/tWqkj45ZCUHf55EK+4Ct3fL7gS9Wd4VjhZp1zN0pjF9jEPIr/Zzti0477qo6UVXnVdXGqtrI4NrE+6rqwNKUOxR9vr9/i8HFd5Kcx+BUzmOLWuVw9Rnz48ClAEnezCDo/8+iVrm49gEf7O6+uQQ4UVVPDWvny/7UTZ3ikQpJ/jVwoKr2Abcy+NXuEIOZ/NVLV/HC9RzzfwDWAv+1u+78eFW9b8mKHoKe425KzzH/DvAjSR4Cvgv8TFX9xdJVvTA9x3wD8J+T/HMGpzCuXcmTtyS/yeDU23nddYefA14OUFW/yuA6xOXAIeA54LqhHn8Ff+0kST2shFM3kqQFMOglqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4/4fy+5pHXEZ1ugAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(xgb_probs.tolist(),columns=['p_churn']).hist(bins=30)\n",
    "plt.x_label = 'predicted probability of churn'\n",
    "plt.y_label = 'count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_features_input(Age,IsActiveMember,NumOfProducts,Germany,Gender,Balance,HasCrCard,Tenure):\n",
    "    \"\"\"Function to handle user inputs of features.\n",
    "    \n",
    "    Args:\n",
    "        Age (str): Age of the customer.\n",
    "        IsActiveMember (str): Whether or not the customer is an active member.\n",
    "        NumOfProducts (str): Number of bank products the customer is using.\n",
    "        Germany (str): Whether or not the customer is a German customer.\n",
    "        Gender (str): Gender of the customer.\n",
    "        Balance (str): Balance left on customer's account.\n",
    "        HasCrCard (str): Whether or not the customer has a credit card.\n",
    "        Tenure (str): How long the customer has been with the bank.\n",
    "        \n",
    "    Returns:\n",
    "        inputs (list): A list of input features.\n",
    "    \n",
    "    \"\"\"\n",
    "    # valid inputs for binary variables\n",
    "    valid_binary = [\"0\",\"1\"]\n",
    "    \n",
    "    inputs = []\n",
    "    \n",
    "    # Age - int\n",
    "    try:\n",
    "        age = int(Age)\n",
    "        if age >= 0 and age <= 110:\n",
    "            inputs.append(age)\n",
    "        else:\n",
    "            return 'Invalid input for Age, must be an integer between 0 and 110!'\n",
    "    except:\n",
    "        return 'Please input a numeric value!'\n",
    "    \n",
    "    # IsActiveMember - binary\n",
    "    try:\n",
    "        if IsActiveMember in valid_binary:\n",
    "            inputs.append(int(IsActiveMember))\n",
    "        else:\n",
    "            return 'Invalid input for IsActiveMember, must be either 0 or 1!'\n",
    "    except:\n",
    "        return 'Please input a numeric value, either 0 or 1!'\n",
    "    \n",
    "    # NumOfProducts - int\n",
    "    try:\n",
    "        numofproducts = int(NumOfProducts)\n",
    "        if numofproducts >= 0:\n",
    "            inputs.append(numofproducts)\n",
    "        else:\n",
    "            return 'Invalid input for NumOfProducts, must be an integer greater than 0!'\n",
    "    except:\n",
    "        return 'Please input a numeric value!'\n",
    "    \n",
    "    # Germany - binary\n",
    "    try:\n",
    "        if Germany in valid_binary:\n",
    "            inputs.append(int(Germany))\n",
    "        else:\n",
    "            return 'Invalid input for Germany, must be either 0 or 1!'\n",
    "    except:\n",
    "        return 'Please input a numeric value, either 0 or 1!'\n",
    "    \n",
    "    # Gender - binary - Male is 1\n",
    "    try:\n",
    "        if Gender in valid_binary:\n",
    "            inputs.append(int(Gender))\n",
    "        else:\n",
    "            return 'Invalid input for Gender, must be either 0 or 1!'\n",
    "    except:\n",
    "        return 'Please input your gender!'\n",
    "    \n",
    "    # Balance - float\n",
    "    try:\n",
    "        balance = float(Balance)\n",
    "        if balance >= 0:\n",
    "            inputs.append(balance)\n",
    "        else:\n",
    "            return 'Invalid input for balance, must be nonnegative!'\n",
    "    except:\n",
    "        return 'Please input a numeric value!'\n",
    "    \n",
    "    # HasCrCard - binary\n",
    "    try:\n",
    "        if HasCrCard in valid_binary:\n",
    "            inputs.append(int(HasCrCard))\n",
    "        else:\n",
    "            return 'Invalid input for HasCrCard, must be either 0 or 1!'\n",
    "    except:\n",
    "        return 'Please input a numeric value, either 0 or 1!'\n",
    "    \n",
    "    # Tenure - int\n",
    "    try:\n",
    "        tenure = int(Tenure)\n",
    "        if tenure >= 0:\n",
    "            inputs.append(tenure)\n",
    "        else:\n",
    "            return 'Invalid input for Tenure, must be an integer greater than 0!'\n",
    "    except:\n",
    "        return 'Please input a numeric value!'\n",
    "    \n",
    "    return inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
